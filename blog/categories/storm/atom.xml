<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: storm | Prashanth Babu]]></title>
  <link href="http://p7h.org/blog/categories/storm/atom.xml" rel="self"/>
  <link href="http://p7h.org/"/>
  <updated>2015-01-15T16:46:58+00:00</updated>
  <id>http://p7h.org/</id>
  <author>
    <name><![CDATA[Prashanth Babu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Udacity course on Apache Storm]]></title>
    <link href="http://p7h.org/blog/2014/12/07/udacity-course-on-apache-storm/"/>
    <updated>2014-12-07T00:00:00+00:00</updated>
    <id>http://p7h.org/blog/2014/12/07/udacity-course-on-apache-storm</id>
    <content type="html"><![CDATA[<div class="post">
<div style="font-size: 15px; white-space: normal;"><span style="font-family: Roboto;">I am a huge fan of <a href="http://storm.apache.org/" target="_blank">Apache Storm</a> for its simplicity and ease of use and more so the uncomplicated way of solving Big Data problems. I have given a <a href="https://fifthelephant.in/2013/workshops" target="_blank">session</a> on this at Fifth Elephant, 2013 too. <br />For all Big Data projects I always try to utilize Storm whenever we deal with any real-time streaming use cases as such. Storm is good and a well-designed tool for solving real-time streaming issues and hence the reason its dubbed as <i>Hadoop of the real-time</i>. I have open sourced many projects on my <a href="https://github.com/P7h" target="_blank">GitHub account</a> which use Storm as the processing engine.<br /><br /><a href="https://www.udacity.com/" target="_blank">Udacity</a> is one of the 3 wonderful MOOCs we have right now, which also include Coursera and edX. Udacity already has a course on Apache Hadoop titled, &#8221;<a href="https://www.udacity.com/course/ud617" target="_blank">Intro to Hadoop and MapReduce</a>&#8221;. Udacity created this course collaborating with <a href="http://www.cloudera.com/" target="_blank">Cloudera</a>. I have done this course last year though I have not opted for the [paid] verified certificate for this course, since I am already a Cloudera Certified Developer for Apache Hadoop [CCDH]. You can find the solutions to all the assignments of this course also on my GitHub account.<!--more--><br /><br />Now Udacity has started a <a href="https://www.udacity.com/course/ud381" target="_blank">new course</a> on Storm, as part of their <a href="https://www.udacity.com/courses#!/data-science" target="_blank">Data Science catalog</a>. This particular course is in partnership with Twitter. Just in case if you are not aware, Storm was open sourced at Twitter and they are one of the power users of Storm for their use cases. Hence it makes great sense to have them teach and talk about Storm. And also the syllabus looks really interesting.<br /></span><br /><blockquote class="tr_bq" style="background-color: white; box-sizing: border-box; color: #303030; font-family: Roboto, 'Whitney SSm A', 'Whitney SSm B', 'Helvetica Neue', Helvetica, Arial, sans-serif; font-size: 14px; line-height: 23.7999992370605px; margin-bottom: 15px;"><span style="font-family: Roboto;"><b>Lesson 1</b></span><br /><span style="font-family: Roboto;">Join instructor Karthik Ramasamy and the first Udacity-Twitter Storm Hackathon to cover the motivation and practice of real-time, distributed, fault-tolerant data processing. Dive into basic Storm Topologies by linking to a real-time d3 Word Cloud Visualization using Redis, Flask, and d3.</span><br /><span style="font-family: Roboto;"><b>Lesson 2</b></span><br /><span style="font-family: Roboto;">Explore Storm basics by programming Bolts, linking Spouts, and finally connecting to the live Twitter API to process real-time tweets. Explore open source components by connecting a Rolling Count Bolt to your topology to visualize Rolling Top Tweeted Words.</span><br /><span style="font-family: Roboto;"><b>Lesson 3</b></span><br /><span style="font-family: Roboto;">Go beyond Storm basics by exploring multi-language capabilities to download and parse real-time Tweeted URLs in Python using Beautiful Soup. Integrate complex open source bolts to calculate Top-N words to visualize real-time Top-N Hashtags. Finally, use stream grouping concepts to easily create streaming join to connect and dynamically process multiple streams.</span><br /><span style="font-family: Roboto;"><b>Lesson 4</b></span><br /><span style="font-family: Roboto;">Work on your final project and we cover additional questions and topics brought up by Hackathon participants. Explore Vagrant, VirtualBox, Redis, Flask, and d3 further if you are interested!</span></blockquote><span style="font-family: Roboto;"><br />I am really excited about this course and I am already half-way thru with the first lesson and its pretty pleasant experience till now.</span><br /><div><span style="font-family: Roboto;"><br /></span></div><div><span style="font-family: Roboto;">Unfortunately, this course does not cover few of the important topics of Storm like Ack, Cluster and Trident. That&#8217;s a dampener for an otherwise some pretty great content. Needless to say, if they would have included these wonderful topics, this course would have been a really wonderful course and a go-to one for any Storm related course on the internet. But alas!</span></div><div><span style="font-family: Roboto;"><br /></span></div><div><span style="font-family: Roboto;">Anyways, I am planning to go ahead and complete the course by the end of this month and if the course guidelines permit, I will put the solutions of the assignments up on my GitHub account.</span><span style="font-family: Roboto;"></span><br /><div><span style="font-family: Roboto;"><br />If you are interested in or your work includes solving real-time Big Data use cases, you might want to checkout this course: <a href="https://www.udacity.com/course/ud381">https://www.udacity.com/course/ud381</a>. </span><br /><div><span style="font-family: Roboto;"><br /></span></div><div><span style="font-family: Roboto;">Happy learning!&nbsp;</span><span style="font-family: Roboto;">And all the very best too.</span></div></div></div></div></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Presented Storm at The Fifth Elephant, 2013 ]]></title>
    <link href="http://p7h.org/blog/2013/07/15/presented-storm-at-fifth-elephant-2013/"/>
    <updated>2013-07-15T00:00:00+01:00</updated>
    <id>http://p7h.org/blog/2013/07/15/presented-storm-at-fifth-elephant-2013</id>
    <content type="html"><![CDATA[<div class="post">
<div style="font-family: Roboto; font-size: 15px; white-space: normal;">On 11th July, 2013 I hosted a workshop on &#8220;Big Data, Real-time Processing and Storm&#8221;at <a href="http://fifthelephant.in/2013/workshops" target="_blank"><strong>The Fifth Elephant, 2013</strong></a> here in Bangalore.<br /><br /><iframe allowfullscreen="" frameborder="0" height="486" marginheight="0" marginwidth="0" mozallowfullscreen="" scrolling="no" src="http://www.slideshare.net/slideshow/embed_code/24202814?rel=0" style="border-width: 1px 1px 0; border: 1px solid #CCC; margin-bottom: 5px;" webkitallowfullscreen="" width="650px"> </iframe> <br /><div style="margin-bottom: 5px;"><div style="text-align: center;"><strong> <a href="http://www.slideshare.net/prashanthvvbabu/fifth-elephant-2013-storm" target="_blank" title="Storm @ Fifth Elephant 2013">Storm @ Fifth Elephant 2013</a> </strong> from <strong><a href="http://www.slideshare.net/prashanthvvbabu" target="_blank">Prashanth Babu</a></strong><!--more--><br /><div style="text-align: justify;">I have also uploaded the slides of the presentation deck to <strong><a href="https://speakerdeck.com/p7h/big-data-real-time-processing-and-storm" target="_blank">SpeakerDeck</a></strong>.</div><br /><div>The source code I used in this workshop can be found on my <strong><a href="http://github.com/P7h" target="_blank">GitHub</a></strong> account.</div><br />I have also started curating a <a href="http://j.mp/YrDgcs" target="_blank"><strong>Bit.ly bundle</strong></a> for Storm and Big Data as such. <br /></div></div>
</div></div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My upcoming workshop on Storm at The Fifth Elephant, 2013]]></title>
    <link href="http://p7h.org/blog/2013/05/25/workshop-on-storm-at-fifth-elephant/"/>
    <updated>2013-05-25T00:00:00+01:00</updated>
    <id>http://p7h.org/blog/2013/05/25/workshop-on-storm-at-fifth-elephant</id>
    <content type="html"><![CDATA[<div class="post">
<div style="font-family: Roboto; font-size: 15px; white-space: normal;"><div style="text-align: justify;"><a href="http://fifthelephant.in/2013/" target="_blank">The Fifth Elephant</a> is a conference in Bangalore, India which focuses on Big Data and Analytics. Its a community powered conference. This means, as highlighted in their website, it is &#8220;Of the Community, By the Community, For the Community&#8221;. So, any one can propose a session as such for the conference in the <a href="http://funnel.hasgeek.com/fifthel2013/" target="_blank">Funnel</a>. Participants who have purchased conference tickets can vote on session proposals.</div><div style="text-align: justify;"><br /></div><div><div style="text-align: justify;">In <a href="http://fifthelephant.in/2012/" target="_blank">2012 edition</a>, Fifth Elephant with more than 50 sessions, attracted 600+ participants from many MNCs, startups alike. This 2-day conference was preceded by a one-day workshop sessions as well due to the overwhelming demand. The biggest USP of any of the HasGeek organized conferences [other than being community powered conferences] is, they live stream most of the sessions and they also upload all the recorded videos to <a href="http://www.youtube.com/user/hasgeek/videos" target="_blank">Youtube</a> and / or&nbsp;<a href="http://hasgeek.tv/fifthelephant/" target="_blank">HasGeek TV</a>.</div></div><div style="text-align: justify;"><br /></div><div><div style="text-align: justify;">I gave a session on <i>Introduction to Pig</i>&nbsp;at The Fifth Elephant last year. I have written about it previously&nbsp;<a href="http://p7h.blogspot.in/2013/01/intro-to-pig.html" target="_blank">here</a>.</div><div style="font-family: Roboto; font-size: 15px; white-space: normal;"></div><div style="text-align: justify;"><br /></div><!--more--><div><div style="text-align: justify;">The Fifth Elephant is back this year. Its even better with a dedicated day for Workshops at the same venue and the regular 2-day Conference on Big Data, Storage and Analytics and also with the product demos and hacker corners. There are some wonderful sessions proposed including one on Neo4J, Julia, etc and few sessions have already been selected by the Program Committee.</div></div></div><div style="text-align: justify;"><br /></div><div><div style="text-align: justify;">I have been working on Big Data especially on Hadoop Ecosystem since more than 2 years now. I am fascinated by Big Data and various tools / frameworks which help analyze such large amounts of data. During this time, I came across <a href="http://storm-project.net/" target="_blank">Storm</a>, which not just analyzes the Big Data, but analyzes in real-time. Yes, real-time very unlike Hadoop, which is basically batch-processing. I worked on couple of use cases and processed the streaming live data in really real-time using Storm. I can quote streaming tweets as my main source of real-time data , which I processed for multiple use cases using Storm.</div></div><div style="text-align: justify;"><br /></div><div><div style="text-align: justify;">This year I have proposed a session on Storm titled <a href="http://funnel.hasgeek.com/fifthel2013/652-big-data-real-time-processing-and-storm" target="_blank">&#8220;Big Data, Real-time Processing and Storm&#8221;</a>&nbsp;and it has been accepted as the first workshop this time around. I will be speaking on 11th July, 2013. It will be a live-coding session, which will help the participants understand and appreciate Storm as one of the better alternatives of Hadoop. Below is the outline of this workshop.</div></div><iframe allowfullscreen="" frameborder="0" height="486" marginheight="0" marginwidth="0" mozallowfullscreen="" scrolling="no" src="http://www.slideshare.net/slideshow/embed_code/17823469?rel=0" style="border-width: 1px 1px 0; border: 1px solid #CCC; margin-bottom: 5px;" webkitallowfullscreen="" width="650px"> </iframe> <br /><div style="margin-bottom: 5px;"><div style="text-align: center;"><strong> <a href="http://www.slideshare.net/prashanthvvbabu/big-data-realtime-processing-and-storm" target="_blank" title="Big Data, Real-time Processing and Storm">Big Data, Real-time Processing and Storm</a> </strong> from <strong><a href="http://www.slideshare.net/prashanthvvbabu" target="_blank">Prashanth Babu</a></strong> </div><br /><div style="text-align: justify;">I have also uploaded the slides of the outline of this workshop to <a href="https://speakerdeck.com/p7h/big-data-real-time-processing-and-storm" target="_blank">SpeakerDeck</a>.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Check the above slides and do let me know if you have any feedback and / or comments on this outline for the workshop.</div><div style="text-align: justify;"><br /></div><div style="text-align: justify;">Wish me good luck on&nbsp;<a href="https://twitter.com/P7h" target="_blank">@P7h</a>. And also if you happen to be there in this Conference, do come and say hi.</div></div><br /><strong>Update</strong>:<br />Please find the complete slides of this workshop session <a href="http://p7h.blogspot.in/2013/07/presented-storm-at-fifth-elephant-2013.html" target="_blank">here</a>. <br /></div></div>
]]></content>
  </entry>
  
</feed>

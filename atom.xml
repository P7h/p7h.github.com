<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Prashanth Babu]]></title>
  <link href="http://p7h.org/atom.xml" rel="self"/>
  <link href="http://p7h.org/"/>
  <updated>2016-01-22T01:29:15+00:00</updated>
  <id>http://p7h.org/</id>
  <author>
    <name><![CDATA[Prashanth Babu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Generating Random numbers in a Range in Java]]></title>
    <link href="http://p7h.org/blog/2016/01/22/generating-random-numbers-in-a-range/"/>
    <updated>2016-01-22T01:22:05+00:00</updated>
    <id>http://p7h.org/blog/2016/01/22/generating-random-numbers-in-a-range</id>
    <content type="html"><![CDATA[<p>Generating random numbers is usually a pain.<br />
And more so when you have generate random numbers in a given range in Java. You have to consider a lot of parameters.</p>

<h3 id="java--v8">Java (&lt; v8)</h3>
<p>I would write something quick and dirty like the following.<br />
For brevity, programming language syntax chosen is Scala, but you get the point.</p>

<pre><code>val random = new java.util.Random
val (size, min, max) = (10, 20, 50)
for(i &lt;- 0 until size) yield (min + random.nextDouble() * (max-min)).toInt

// Output of the above code in Scala REPL
res1: scala.collection.immutable.IndexedSeq[Int] = Vector(46, 38, 22, 21, 43, 35, 49, 47, 23, 41)
</code></pre>

<!--more-->

<h3 id="python">Python</h3>
<p>Python has core library support for this feature. So, we can do the following:</p>

<pre><code>from random import randint
[randint(10, 50) for p in range(10)]

## Output of the above code in Python REPL
[43, 33, 37, 20, 41, 11, 18, 25, 12, 26]
</code></pre>

<p>But wont it be cool if we had such an utility in the JDK itself as in Python to generate random numbers? So, this is where JDK v8 comes to help.</p>

<h3 id="java-v8x-new-methods">Java v8.x new methods</h3>
<p>JDK v8 added the following nifty methods to <code>java.util.Random</code> class which help us in accomplishing this.</p>

<ol>
  <li>Generate an unlimited number of random values »» <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Random.html#ints--">public IntStream ints()</a></li>
  <li>Generate an unlimited number of random values within a range »» <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Random.html#ints-int-int-">public IntStream ints (int randomNumberOrigin, int randomNumberBound)</a></li>
  <li>Generate ‘n’ random integers »» <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Random.html#ints-long-">public IntStream ints(long streamSize)</a></li>
  <li>Generate ‘n’ random integers in a given range »» <a href="https://docs.oracle.com/javase/8/docs/api/java/util/Random.html#ints-long-int-int-">public IntStream ints(long streamSize, int randomNumberOrigin, int randomNumberBound)</a></li>
</ol>

<p>Also, similar utility methods are present for <code>long</code> and <code>double</code> datatypes respectively.<br /></p>

<p>Please take a note that each of these methods are actually returning an <code>java.util.stream.IntStream</code> and not an <code>Array</code>.<br />
And another point to note here is: <code>[randomNumberOrigin, randomNumberBound)</code> i.e. random numbers generated will be <code>randomNumberOrigin ≤ x &lt; randomNumberBound</code>.</p>

<h3 id="code-with-java-v8">Code with Java v8</h3>
<p>So, with this background we can modify our initial code to utilize the new(ish) Java API directly:</p>

<pre><code>val random = new java.util.Random
val (size, min, max) = (10, 20, 50)
random.ints(size, min, max).toArray  

// Output of the above code in Scala REPL
res2: Array[Int] = Array(21, 43, 48, 33, 32, 48, 27, 25, 46, 32)
</code></pre>

<p>And similarly we can check the other methods as well.</p>

<pre><code>random.longs(size, min, max).toArray
res3: Array[Long] = Array(32, 44, 24, 34, 40, 29, 45, 24, 43, 30)

random.doubles(3, min, max).toArray
res4: Array[Double] = Array(38.10858166740068, 22.464983440394192, 43.64737980712431)
</code></pre>

<p>Fairly simple and no need to reinvent the wheel.<br />
Happy learning!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[DataStax Cassandra Online Courses]]></title>
    <link href="http://p7h.org/blog/2015/03/27/datastax-cassandra-online-courses/"/>
    <updated>2015-03-27T23:54:40+00:00</updated>
    <id>http://p7h.org/blog/2015/03/27/datastax-cassandra-online-courses</id>
    <content type="html"><![CDATA[<p>I recently attended few online courses of DataStax around Cassandra. This post is about my experiences and review of these courses.</p>

<p>Late in February, I came across <a href="https://twitter.com/tlberglund/status/570002948056621056" title="DataStax Courses">this tweet</a> in my timeline.</p>

<blockquote>
  <p>Tim Berglund ‏<a href="https://twitter.com/tlberglund/status/570002948056621056">@tlberglund</a>: When I first started at @datastax, I never dreamed we’d get here. But we did! All online training is now free: <a href="http://datastax.com/training">http://datastax.com/training</a></p>
</blockquote>

<!--more-->
<p>Out of curiosity I checked the link and was kinda shocked to see so many wonderful courses being offered online for free. I was just starting to work on Cassandra then and this was a great chance for me to learn more and hone Cassandra for my regular Big Data work and also for overall understanding of one of the best NoSQL databases.</p>

<p>As I am a Big Data and Hadoop Ecosystem guy, I am more interested in getting to know how to go around Cassandra, use Cassandra for data pipelines and of course installation, tuning and tweaking of Cassandra for throughput. So, I enrolled myself for the following 3 courses:</p>

<ol>
  <li>DS201: Cassandra Core Concepts Skills and Tools.</li>
  <li>DS210: DataStax Enterprise Operations and Performance.</li>
  <li>DS320: DataStax Enterprise Analytics: Spark and Cassandra.</li>
</ol>

<p>Below is a quick review of the objectives and my experiences of these courses I attended and a bit of feedback to DataStax Training team.</p>

<p>All the courses were online and were on WebEx, which really helps people to attend from anywhere without using any custom software or tools except for browser.</p>

<h4 id="ds201-cassandra-core-concepts-skills-and-tools">DS201: Cassandra Core Concepts Skills and Tools</h4>

<ul>
  <li>Course details: <a href="http://www.datastax.com/what-we-offer/products-services/training/apache-cassandra-core-concepts-skills-and-tools">DataStax course page</a>.</li>
  <li>Instructor: Ron Cohen.</li>
  <li>Date: 02<sup>nd</sup> March to 05<sup>th</sup> March, 2015.</li>
  <li>Duration: 3 hours per day.</li>
  <li>Time: 10:00 AM to 01:00 PM GMT. </li>
</ul>

<p>This course, as the name indicates is more for basics and concepts of Cassandra. The course material and the way Ron went about building the course was really great. </p>

<p>Training team sent the participants a link for the CassandraVM 2 days before the class. We were also provided a download link for the slides and workbooks of the course before the start of the course. Slides are the handouts of the course; while workbooks are the exercises which you need to do at the end of the day at your convenience on the CassandraVM.</p>

<p>This course rightly set the tone for the rest of the courses I wanted to attend. And the exercises helped me too.</p>

<p>Ron was very understanding and he spent quite a good amount of time clarifying a number of questions during the course.</p>

<h4 id="ds210-datastax-enterprise-operations-and-performance">DS210: DataStax Enterprise Operations and Performance.</h4>

<ul>
  <li>Course details: <a href="http://www.datastax.com/what-we-offer/products-services/training/apache-cassandra-operations-and-performance-tuning">DataStax course page</a>.</li>
  <li>Instructor: Kiyu Gabriel.</li>
  <li>Date: 16<sup>th</sup> March to 19<sup>th</sup> March, 2015.</li>
  <li>Duration: 3 hours per day for 4 days.</li>
  <li>Time: 05:00 PM to 08:00 PM GMT.</li>
</ul>

<p>Course details and objectives can be found  for this course.</p>

<p>This course goes a bit in depth and talks a lot about tuning and tweaking the Cassandra installation for better performance. Talks extensively about how to tweak, what to tweak in Cassandra, replication factor and a lot more. Most fascinating topic was on the last day on “Understanding Performance Tuning”.
The day before the training, I received the course decks and exercises related link. </p>

<p>Its unfortunate that I missed few of the sessions due to work conflicts and neither I could do the exercises. So, I am planning to attend this course again in the near future to cover the missed out sessions.</p>

<h4 id="ds320-datastax-enterprise-analytics-spark-and-cassandra">DS320: DataStax Enterprise Analytics: Spark and Cassandra</h4>

<ul>
  <li>Course details: <a href="http://www.datastax.com/what-we-offer/products-services/training/datastax-enterprise-analytics-spark-and-cassandra">DataStax course page</a>.</li>
  <li>Instructor: Artem Chebotko.</li>
  <li>Date: 23<sup>rd</sup> March to 26<sup>th</sup> March, 2015.</li>
  <li>Duration: 3 hours per day for 4 days.</li>
  <li>Time: 03:00 PM to 06:00 PM GMT.</li>
</ul>

<p>We received the course decks and the exercises, few hours before the course started. And from then on, it was really a ride.
The way the course is structured and the way Artem took the participants was really wonderful. This is, by far, probably the best online course I have ever attended.</p>

<p>At the end of first day, each course participant also received access to a decently configured 3-node DataStax Enterprise Cluster hosted on AWS EC2 for which DataStax would have paid a lot of money to Amazon. This was really a great thing since this cluser has DataStax Cassandra and <em>also</em> Spark installed and configured on it for our usage. And this was all for us for 4 days. Config of each of the machines was: 4 GB RAM, 30 GB HDD and 14.04 Ubuntu 64-bit Server Edition, which was very decent enough for all our data pipelines. These machines also came with a folder for the exercises and source code for the data generators and data on it.</p>

<p>Needless to say I tried all the course code content and also exercises for each of the days. I played quite a bit with the code snippets from the class. But I have had issues in getting my code right for exercises of Spark PairRDDs, Spark Streaming and Spark SQL. I somehow managed, as-in I tried following the solutions of these exercises and tried understanding the code. But I would have liked to spend more time to develop my own code for these exercises. Someday once understand how these work, I would like to revisit these exercises with a fresh pair of eyes.</p>

<h5 id="feedback-to-datastax-training-team">Feedback to DataStax training team</h5>

<p>After each of the courses, DataStax sends all the participants a survey from SurveyMonkey for their feedback loop and betterment of the courses.</p>

<p>Though all the courses were really good, there are few areas to improve upon for these courses to become perfect courses and for the participants to get more value from the courses and effort and money spent by DataStax.</p>

<p>First and foremost, I thought a lot of content is being crammed into 4 days of training [with 3 hours per day], which is not only difficult to cover; but also tough to digest. Adding to that, the participants usually have a lot of questions. So that too consumes a lot of time. I would think they might have to extend the course by a day and also make it 3.5 or 4 hours per day. That way instructor gets a bit more time to cover topics in depth instead of just skimming. After all, these courses are 3 days in person; effectively ~24 hours. So going by that metrics, probably extending the current 12 hour sessions to at least 15 or 20 hours for online would be really helpful.</p>

<p>My other gripe was about the course slide decks. The content is absolutely brilliant. But DataStax shares only the handouts, which do not help much since there are not many notes in the slides and also the content gets so small that it cant be read without zooming-in a lot. And even more bigger issue is, handouts do not allow copy + pasting the code contents for practicing either, considering the contents in the handouts gets saved as images and not as text. So in all the post-course surveys, I have given this feedback. Hopefully they will soon start sharing the complete PDFs of the course slide decks instead of just the handouts.</p>

<p>Also the sessions are not recorded. I missed out attending few of the days. As such there was no way for me to check back on the day. So it would have been helpful if we had access to the recorded sessions. I also feel it would be really great to refer to the course videos from time to time even otherwise, by going thru the recorded sessions.</p>

<p>That said, it was a great effort by the DataStax Training team and I absolutely loved all the courses and so too the course content, which I will be referring to, henceforth for all my Cassandra related work.</p>

<p>Thank you DataStax Training team!
You guys are doing an amazing job.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Migrating from Blogger to Octopress]]></title>
    <link href="http://p7h.org/blog/2015/01/18/migration-blogger-to-octopress/"/>
    <updated>2015-01-18T16:31:01+00:00</updated>
    <id>http://p7h.org/blog/2015/01/18/migration-blogger-to-octopress</id>
    <content type="html"><![CDATA[<p>So like many others in the blogging world, I too shifted from Blogger to statically generated Octopress hosted on GitHub last week.And today I completed migrating all my <a href="http://P7h.blogspot.com">Blogger</a> posts to <a href="http://P7h.org">Octopress</a> and got them hosted here. Henceforth will leave Blogger as-is and will try to make this as my active blog.<br /></p>

<p>Initially I was kinda apprehensive that I might have to put in significant effort to migrate my posts from Blogger to Octopress. But it turned out to be very simple actually. In fact, it was as simple as running just a single Ruby script.
<!--more--></p>

<p>I have listed below the required steps for migration, just in case if someone needs a ready reference.</p>

<ul>
  <li>Export your content from Blogger:<br />
    <ul>
      <li>Go to Blogger Settings -&gt; Other -&gt; Blog Tools -&gt; Click on “Export blog” link.<br /></li>
      <li>This screenshot might be helpful for reaching this section in Blogger maze.<br />
  <img src="http://p7h.org/assets/images/Blogger_Export_Posts.png" alt="" /></li>
      <li>This downloads an xml file [in the format blog-<em>month</em>-<em>date</em>-<em>year</em>.xml] with all the content from your blogs. In my case, it turned out to be “blog-01-18-2015.xml”.<br /></li>
    </ul>
  </li>
  <li>Ruby script for migration:<br />
    <ul>
      <li>Then get a copy of a Ruby script from this <a href="https://gist.github.com/P7h/6df39591aa5554f4335c" target="_blank">Gist</a> for converting posts from Blogger format to Octopress compatible format.<br /></li>
      <li>Please remember you might need to have nokogiri gem - if not already installed - before moving further. Command to install this gem is: <code>gem install nokogiri</code>.</li>
    </ul>
  </li>
  <li>Execution of Ruby script:<br />
    <ul>
      <li>Run this Ruby script on the xml file you downloaded above. Command for execution is: <code>ruby import.rb blog-01-18-2015.xml</code>.<br /></li>
      <li>This generates the content of your blog in html files.<br /></li>
      <li>During the migration, this script tries to retain the exact same path you would have used in the Blogger script and also tries to get the date [but not time] of the post and categories, etc you would have listed for each of your posts in Blogger. Very neat I would say.<br /></li>
    </ul>
  </li>
  <li>Post generation of posts:<br />
    <ul>
      <li>Copy the generated html files to <code>_source/posts</code> folder in your Octopress folder and you are done.<br /></li>
      <li>Do a <code>rake generate</code> and <code>rake preview</code> and check the blog posts have all come well and confirm if the migration went fine.<br /></li>
      <li>Once you are happy with the migration and content, perform <code>rake deploy</code>.</li>
      <li>And don’t forget to push these changes to GitHub.<br /></li>
    </ul>
  </li>
  <li>Few caveats:<br />
    <ul>
      <li>Please note that all the files usually crated by rake tasks are .md i.e. markdown files while the migrated scripts will be plain html files.<br /></li>
      <li>Also please note that post the migration, all the migrated posts will retain the correct date, but time gets defaulted to 12:00 AM. I could not find time to debug the issue though.<br /></li>
    </ul>
  </li>
</ul>

<p>Hope these steps were useful to you. Enjoy the new blog and glory!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Octopress blogging setup on a new machine]]></title>
    <link href="http://p7h.org/blog/2015/01/16/octopress-setup-windows/"/>
    <updated>2015-01-16T14:48:00+00:00</updated>
    <id>http://p7h.org/blog/2015/01/16/octopress-setup-windows</id>
    <content type="html"><![CDATA[<p>This post gives a brief intro to setting up Octopress blog on a new Windows machine. This assumes you already have your blogs on your GitHub account and are changing the machine or setting up on a new machine.</p>

<h3 id="step-1-install-ruby-v193">Step 1: Install Ruby v1.9.3</h3>

<p>Download and install Ruby v1.9.3 from <a href="http://rubyinstaller.org/downloads/">here</a>. <code>ruby --version</code> should give something on the lines of <code>ruby 1.9.3p551 (2014-11-13) [i386-mingw32]</code>.
<!--more--></p>

<h3 id="step-2-install-rubydevkit">Step 2: Install RubyDevKit</h3>

<p>Download and install Ruby Dev Kit from <a href="https://github.com/downloads/oneclick/rubyinstaller/DevKit-tdm-32-4.5.2-20111229-1559-sfx.exe">here</a></p>

<p>Change the directory to folder where you installed RubyDevKit and then run the following commands:</p>

<pre><code>cd RubyDevKit
ruby dk.rb init
ruby dk.rb install
</code></pre>

<h3 id="step-3-clone-your-repo-and-install-dependencies">Step 3: Clone your repo and install dependencies</h3>

<p>Clone your repository preferably using GitHub client for Windows. Please note you must point to <code>source</code> and not <code>master</code> of your GitHub repo.</p>

<p>Change directory to that folder [in this case, I am referring to my folder as an example; you must change to your appropriate folder] and run the following commands:</p>

<pre><code>cd p7h.github.com
gem install bundler
bundle install
</code></pre>

<h4 id="step-3a-if-you-get-ssl-errors-from-running-the-above-commands">Step 3a: If you get SSL errors from running the above commands</h4>

<p>If the above commands fail, <a href="https://gist.github.com/P7h/fcb67d22aad7f9eee6e7">manually add trust certificate to Rubygems</a> and then retry to install the dependencies with the above commands.</p>

<h3 id="step-4-setup-the-github-pages-and-generate-and-preview-the-blog">Step 4: Setup the GitHub pages and generate and preview the blog</h3>

<p>Run the following commands to complete the blog setup. With preview you can view your blog on your machine on port <a href="http://localhost:4000">4000</a>:</p>

<pre><code>cd p7h.github.com
rake setup_github_pages
rake generate
rake preview
</code></pre>

<h3 id="step-5-github-personal-access-token">Step 5: GitHub Personal Access Token</h3>
<p>If you have enabled 2 FA on GitHub, you must get GitHub access token from <a href="https://github.com/settings/applications">applications</a> page on GitHub. You need to give this access token for user name while performing <code>git commit</code> or <code>rake deploy</code> or <code>rake gen_deploy</code> in the next steps.</p>

<h3 id="step-6-deploy-the-blog">Step 6: Deploy the blog</h3>
<p>Once you are done with all your changes, deploy your changes to your blog by running these commands:</p>

<pre><code>cd p7h.github.com
rake generate
rake deploy
</code></pre>

<p>Or generate and deploy both together with a single command:</p>

<pre><code>cd p7h.github.com
rake gen_deploy
</code></pre>

<h3 id="step-7-commit-your-changes">Step 7: Commit your changes</h3>

<pre><code>cd p7h.github.com
git add -A
git commit -m 'commit message'
git push origin source
</code></pre>

<h3 id="step-8-other-useful-commands">Step 8: Other useful commands</h3>
<p>For creating a new page:</p>

<pre><code>cd p7h.github.com
rake new_page["new page"]
</code></pre>

<p>For creating a new post:</p>

<pre><code>cd p7h.github.com
rake new_post["new post"]
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[JDK installation from ppa on Ubuntu]]></title>
    <link href="http://p7h.org/blog/2015/01/14/jdk-installation-ubuntu-ppa/"/>
    <updated>2015-01-14T17:04:15+00:00</updated>
    <id>http://p7h.org/blog/2015/01/14/jdk-installation-ubuntu-ppa</id>
    <content type="html"><![CDATA[<p>Previously I have <a href="http://p7h.org/blog/2014/10/18/jdk-download-command-prompt/">written</a> how to install Oracle JDK on any env [Linux or Windows] from the command prompt.</p>

<p>But you can do that without even writing a single line of code or anything just by getting the JDK from the ppa on Ubuntu.
So, here are 3 very simple steps for installation of Oracle JDK on a Ubuntu machine.</p>

<!--more-->

<h4 id="initial-setup-command">Initial setup command</h4>
<pre><code>sudo apt-get install python-software-properties
</code></pre>

<h4 id="add-ppa-to-software-sources">Add ppa to software sources</h4>
<pre><code>sudo add-apt-repository ppa:webupd8team/java
sudo apt-get update
</code></pre>

<h4 id="for-oracle-jdk-6x">For Oracle JDK 6.x</h4>
<pre><code>sudo apt-get install oracle-java6-installer
</code></pre>

<h4 id="for-oracle-jdk-7x">For Oracle JDK 7.x</h4>
<pre><code>sudo apt-get install oracle-java7-installer
</code></pre>

<h4 id="for-oracle-jdk-8x">For Oracle JDK 8.x</h4>
<pre><code>sudo apt-get install oracle-java8-installer
</code></pre>

<h4 id="configure-the-env">Configure the env</h4>
<ul>
  <li>Add JAVA_HOME env variable.</li>
  <li>Also add JAVA_HOME/bin to PATH env variable.</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A new blog]]></title>
    <link href="http://p7h.org/blog/2015/01/12/a-new-blog/"/>
    <updated>2015-01-12T00:12:46+00:00</updated>
    <id>http://p7h.org/blog/2015/01/12/a-new-blog</id>
    <content type="html"><![CDATA[<p>This is my first blogpost using Octopress and GitHub.</p>

<p>Previously, I had my blogs hosted on <a href="http://P7h.blogspot.com">Blogger</a>.
Though Blogger engine is good, I could never spend time to create a template on my own to make my blogpage look good and on top of that the default templates and layouting always made go crazy since its too tedious to spend time on fine-tuning and make the page look zazzy. 
<!--more-->
Being a minimalist, I would like to go with minimum cruft and more emphasis on the code and content rather than the styling of the blogpage with an attractive UI.</p>

<p>So here I am, trying to use Octopress and trying to generate static pages using GitHub. I went with default Octopress template. Setting it up on Windows with Ruby was a bit painful initially and I went helter-skelter looking for help mostly with Google and SO. But after 2 trials, I was able to get my default website up and running. I hope this will be a nice experience with just markdown and code-highlighting to the rescue.</p>

<p>Over a period of time or whenever I get time, I will be exporting all my posts from Blogger to GitHub hosted static pages. Though its a considerable effort, I would like to give it a shot and move away from Blogger and maintain this as my primary blogpage.</p>

<p>For now, just “Hello World”. :-)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Udacity course on Apache Storm]]></title>
    <link href="http://p7h.org/blog/2014/12/07/udacity-course-on-apache-storm/"/>
    <updated>2014-12-07T00:00:00+00:00</updated>
    <id>http://p7h.org/blog/2014/12/07/udacity-course-on-apache-storm</id>
    <content type="html"><![CDATA[<p>I am a huge fan of <a href="http://storm.apache.org/" target="_blank">Apache Storm</a> for its simplicity and ease of use and more so the uncomplicated way of solving Big Data problems. I have given a <a href="https://fifthelephant.in/2013/workshops" target="_blank">Storm session</a> at Fifth Elephant, 2013 at Bangalore.</p>

<p>For Big Data projects, I try to utilize Storm whenever we deal with any real-time streaming use cases as such. Storm is good and a well-designed tool for solving real-time streaming issues and hence the reason its dubbed as <i>Hadoop of the real-time</i>. I have open sourced many projects on my <a href="https://github.com/P7h" target="_blank">GitHub</a> which use Storm as the processing engine.<br />
<!--more--></p>

<p><a href="https://www.udacity.com/" target="_blank">Udacity</a> is one of the 3 wonderful MOOCs we have right now, which also include Coursera and edX. Udacity already has a course on Apache Hadoop titled, “<a href="https://www.udacity.com/course/ud617" target="_blank">Intro to Hadoop and MapReduce</a>”. Udacity created this course collaborating with <a href="http://www.cloudera.com/" target="_blank">Cloudera</a>. I have done this course last year though I did not opt for the [paid] verified certificate for this course, since I am already a Cloudera Certified Developer for Apache Hadoop [CCDH]. You can find the solutions to all the assignments of this course also on my GitHub account.<br /></p>

<p>Udacity has started a new course on <a href="https://www.udacity.com/course/ud381" target="_blank">Storm</a>, as part of their <a href="https://www.udacity.com/courses#!/data-science" target="_blank">Data Science catalog</a> in the first week of December, 2013. This particular course is in partnership with Twitter. Just in case, if you are not aware, Storm was open sourced at Twitter and they are one of the power users of Storm for their manyt use cases. Best use case of Twitter usage of Storm is that of real-time hashtags which you see on Twitter. Hence it makes great sense to have them teach and talk about Storm. And also the syllabus looks really interesting.<br /></p>

<p>Here is a brief rundown of the syllabus from Udacity website on Storm course:</p>

<blockquote class="tr_bq" style="background-color: white; box-sizing: border-box; color: #303030; font-size: 14px; line-height: 24px; margin-bottom: 15px;">
<span style="font-weight: bold;">Lesson 1</span><br />
Join instructor Karthik Ramasamy and the first Udacity-Twitter Storm Hackathon to cover the motivation and practice of real-time, distributed, fault-tolerant data processing. Dive into basic Storm Topologies by linking to a real-time d3 Word Cloud Visualization using Redis, Flask, and d3.<br />

<span style="font-weight: bold;">Lesson 2</span><br />
Explore Storm basics by programming Bolts, linking Spouts, and finally connecting to the live Twitter API to process real-time tweets. Explore open source components by connecting a Rolling Count Bolt to your topology to visualize Rolling Top Tweeted Words.<br />

<span style="font-weight: bold;">Lesson 3</span><br />
Go beyond Storm basics by exploring multi-language capabilities to download and parse real-time Tweeted URLs in Python using Beautiful Soup. Integrate complex open source bolts to calculate Top-N words to visualize real-time Top-N Hashtags. Finally, use stream grouping concepts to easily create streaming join to connect and dynamically process multiple streams.<br />

<span style="font-weight: bold;">Lesson 4</span><br />
Work on your final project and we cover additional questions and topics brought up by Hackathon participants. Explore Vagrant, VirtualBox, Redis, Flask, and d3 further if you are interested!
</blockquote>

<p>I am really excited about this course and I am already half-way thru with the first lesson and its a pretty pleasant experience till now.<br /></p>

<p>Unfortunately, this course does not cover few of the important topics of Storm like Ack, Cluster and Trident. That’s a dampener for an otherwise some pretty great content. Needless to say, if they would have included these wonderful topics, this course would have been a really wonderful course and a go-to one for any Storm related course on the internet. But alas!</p>

<p>Anyways I am planning to go ahead and complete the course by the end of this month and if the course guidelines permit, I will put the solutions of the assignments up on my GitHub account.<br /></p>

<p>If you are interested in or your work includes solving real-time Big Data use cases, you might want to checkout this course: <a href="https://www.udacity.com/course/ud381" target="_blank">https://www.udacity.com/course/ud381</a>.<br /></p>

<p>Happy learning! And all the very best too.<br /></p>

<p><em>Updated on 20th January, 2015</em>: I have uploaded my code and solutions for the exercises, while working on this course to <a href="https://github.com/P7h/Real-Time_Analytics_with_Apache_Storm__Udacity_Course" title="Real-Time Analytics with Apache Storm">GitHub</a>. Please check it, you may find it useful.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Download Java / JDK / JRE from shell / terminal / command prompt]]></title>
    <link href="http://p7h.org/blog/2014/10/18/jdk-download-command-prompt/"/>
    <updated>2014-10-18T00:00:00+01:00</updated>
    <id>http://p7h.org/blog/2014/10/18/jdk-download-command-prompt</id>
    <content type="html"><![CDATA[<p>Its been really sometime since I blogged anything. Got into too much work both on personal and professional fronts. I will try to be regular henceforth though, hopefully [fingers crossed!!].<br /></p>

<p>Most of my work happens on EC2 and on Linux as our Hadoop env is on EC2. I absolutely adore Linux and shell. And first and foremost thing I have to do - being a Java developer - is download Oracle JDK onto the Linux machines on EC2. And downloading Oracle JDK from Oracle website is difficult due to Oracle’s mandatory license check, which you need to accept before downloading the JDK. With my Linux env being server-only-machines [i.e. without a desktop or GUI], there is no way I could download the JDK directly from Oracle website. So, I came up with this small shell script [extending an <a href="http://stackoverflow.com/a/10959815" target="_blank">answer</a> from Stackoverflow] to download JDK from Oracle website from command prompt.<!--more--><br /></p>

<p>Depending on the OS and platform of the JDK version you intend to download, just modify the array on line#20 in the following script and you can trigger the download on the shell directly.</p>
<div><script src="https://gist.github.com/9741922.js?file=jdk_download.sh"></script>
<noscript><pre><code>#####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####

### Shell script to download Oracle JDK / JRE / Java binaries from Oracle website using terminal / command / shell prompt using wget.
### You can download all the binaries one-shot by just giving the BASE_URL.
### Script might be useful if you need Oracle JDK on Amazon EC2 env.
### Script is updated for every JDK release.

### Features:-
# 1. Resumes a broken / interrupted [previous] download, if any.
# 2. Renames the file to a proper name with including platform info.
# 3. Downloads the following from Oracle Website with one shell invocation.
#    a. Windows 64 and 32 bit;
#    b. Linux 64 and 32 bit;
#    c. API Docs;
#    d. You can add more to the list of downloads are per your requirement.
### Another option: 
###### curl -L -O -H &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; -k &quot;http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60-linux-x64.tar.gz&quot;

#####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####

## Latest JDK8 version released on 19th January, 2016: JDK8u71
BASE_URL_8=http://download.oracle.com/otn-pub/java/jdk/8u71-b15/jdk-8u71

## Earlier versions:
## v8u65 =&gt; http://download.oracle.com/otn-pub/java/jdk/8u65-b17/jdk-8u65
## v8u60 =&gt; http://download.oracle.com/otn-pub/java/jdk/8u60-b27/jdk-8u60
## v8u51 =&gt; http://download.oracle.com/otn-pub/java/jdk/8u51-b16/jdk-8u51
## v8u45 =&gt; http://download.oracle.com/otn-pub/java/jdk/8u45-b14/jdk-8u45
## v8u40 =&gt; http://download.oracle.com/otn-pub/java/jdk/8u40-b25/jdk-8u40
## v8u31 =&gt; http://download.oracle.com/otn-pub/java/jdk/8u31-b13/jdk-8u31
## v8u25 =&gt; http://download.oracle.com/otn-pub/java/jdk/8u25-b17/jdk-8u25

JDK_VERSION=${BASE_URL_8: -8}

declare -a PLATFORMS=(&quot;-windows-x64.exe&quot; &quot;-linux-x64.tar.gz&quot; &quot;-docs-all.zip&quot; &quot;-windows-i586.exe&quot; &quot;-linux-i586.tar.gz&quot;)

for platform in &quot;${PLATFORMS[@]}&quot;
do
    wget -c -O &quot;$JDK_VERSION$platform&quot; --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; &quot;${BASE_URL_8}${platform}&quot;
    ### curl -L -O -H &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; -k &quot;${BASE_URL_8}${platform}&quot;
done

#####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####   #####</code></pre></noscript></div>

<p>Hope this script will be helpful for all those who live on and love command prompt.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Learning Guava -- Calibrating time using Stopwatch]]></title>
    <link href="http://p7h.org/blog/2014/01/29/guava-stopwatch/"/>
    <updated>2014-01-29T00:00:00+00:00</updated>
    <id>http://p7h.org/blog/2014/01/29/guava-stopwatch</id>
    <content type="html"><![CDATA[<p>Many of our day-to-day applications would need calibrating time taken between 2 points. In Java world we either depend on <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/System.html#currentTimeMillis()" target="_blank"><code>System.currentTimeMillis()</code></a> or <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/System.html#nanoTime()" target="_blank"><code>System.nanoTime()</code></a>. But the pain here is, we have to do the required computations of getting to a proper granularity to understand the time taken. Would n’t it be great it to have such an utility class which will give the required information in the granularity we need with minimum amount of boilerplate code?<br /><br /><a href="http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/base/Stopwatch.html" target="_blank"><code>Stopwatch</code></a> is one such small and wonderful utility class in Guava which helps in calibrating elapsed time / duration between any 2 points in the logic. The advantage of using Guava’s <code>Stopwatch</code> is you can get the elapsed time in any measure i.e. right from nanoseconds to days. This is possible because you can pass an enum argument type of <a href="http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/TimeUnit.html" target="_blank"><code>TimeUnit</code></a> class to get the elapsed time in the desired granularity.
<!--more-->
Code snippet for the usage of the <code>Stopwatch</code> class:</p>
<div><script src="https://gist.github.com/8691100.js"></script>
<noscript><pre><code>import java.util.Random;
import java.util.concurrent.TimeUnit;

import com.google.common.base.Stopwatch;

/**
 * Sample example demonstrating usage of Stopwatch API of Google Guava.
 *
 * @see &lt;a href=&quot;http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/base/Stopwatch.html&quot;&gt;Guava Stopwatch&lt;/a&gt;
 */
public final class StopwatchExample {

	public final static void main(final String[] args) {
		//Effective Guava v15.0, this is the one way of creating a Stopwatch instance.
		final Stopwatch stopwatch = Stopwatch.createStarted();

		//Sleep for few random milliseconds.
		try {
			Thread.sleep(new Random().nextInt(1000));
		} catch (final InterruptedException interruptedException) {
			interruptedException.printStackTrace();
		}

		stopwatch.stop(); //optional

		System.out.println(&quot;Elapsed time ==&gt; &quot; + stopwatch);
		System.out.println(&quot;Elapsed time in Nanoseconds ==&gt; &quot; + stopwatch.elapsed(TimeUnit.NANOSECONDS));
		System.out.println(&quot;Elapsed time in Microseconds ==&gt; &quot; + stopwatch.elapsed(TimeUnit.MICROSECONDS));
		System.out.println(&quot;Elapsed time in Milliseconds ==&gt; &quot; + stopwatch.elapsed(TimeUnit.MILLISECONDS));
		//System.out.println(&quot;Elapsed time in Seconds ==&gt; &quot; + stopwatch.elapsed(TimeUnit.SECONDS));
		//System.out.println(&quot;Elapsed time in Minutes ==&gt; &quot; + stopwatch.elapsed(TimeUnit.MINUTES));
	}
}</code></pre></noscript></div>

<p>Few caveats for using <code>Stopwatch</code> are you should not start an already started <code>Stopwatch</code>. One has to check if the <code>Stopwatch</code> is already running by invoking <a href="http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/base/Stopwatch.html#isRunning()" target="_blank"><code>isRunning()</code></a> method. <code>Stopwatch</code> documentation says the following on the same:<br />
&lt;blockquote class=&#8221;tr_bq&#8221; style=&#8221;background-color: white; box-sizing: border-box; color: #303030; font-size: 14px; line-height: 24px; margin-bottom: 15px;&#8221;&gt;Stopwatch methods are not idempotent; it is an error to start or stop a stopwatch that is already in the desired state.&lt;/blockquote&gt;
Also, once I got burned down by <a href="http://commons.apache.org/proper/commons-lang/javadocs/api-3.2.1/org/apache/commons/lang3/time/StopWatch.html" target="_blank"><code>StopWatch</code></a> class of Apache Commons Lang. As I was working in an IDE on a Maven project, I could not quickly relate to the difference between <code>Stopwatch</code> of Guava and <code>StopWatch</code> of Apache Commons Lang, as the class got auto imported into the code and then spent some good 20 minutes trying to check my classpath, IDE setup, etc. Yes very silly mistake. So, please be careful in choosing the correct class.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Learning Guava -- Load properties file using Guava]]></title>
    <link href="http://p7h.org/blog/2014/01/26/load-properties-file-using-guava/"/>
    <updated>2014-01-26T00:00:00+00:00</updated>
    <id>http://p7h.org/blog/2014/01/26/load-properties-file-using-guava</id>
    <content type="html"><![CDATA[<p>Guava code snippet for loading a properties file from classpath.<br />
<!--more--></p>
<div><script src="https://gist.github.com/8635204.js"></script>
<noscript><pre><code>import java.io.IOException;
import java.io.InputStream;
import java.net.URL;
import java.util.Properties;

import com.google.common.io.ByteSource;
import com.google.common.io.Resources;

/**
 * Reads a properties file and print all the key value pairs to the console.
 * Note: Writing to console is just for convenience here.
 */
public final class ReadPropertiesWithGuava {

	public final static void main(final String[] args) {
		final URL url = Resources.getResource(&quot;spring-config.properties&quot;);
		final ByteSource byteSource = Resources.asByteSource(url);
		final Properties properties = new Properties();
		InputStream inputStream = null;
		try {
			inputStream = byteSource.openBufferedStream();
			properties.load(inputStream);
			properties.list(System.out);
		} catch (final IOException ioException) {
			ioException.printStackTrace();
		} finally {
			if (inputStream != null) {
				try {
					inputStream.close();
				} catch (final IOException ioException) {
					ioException.printStackTrace();
				}
			}
		}
	}
}</code></pre></noscript></div>

<p>For more info, please check <a href="http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/io/Resources.html" target="_blank">Resources</a> class of Guava.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Learning Guava -- Google Guava blog series]]></title>
    <link href="http://p7h.org/blog/2013/11/27/google-guava-posts/"/>
    <updated>2013-11-27T00:00:00+00:00</updated>
    <id>http://p7h.org/blog/2013/11/27/google-guava-posts</id>
    <content type="html"><![CDATA[<p>​I have been a huge fan of <a href="https://code.google.com/p/guava-libraries/" style="font-family: Roboto; font-size: 15px;" target="_blank">Google Guava</a> from the time I came across it 3 years back.<br />For starters, Guava is a project which contains many Google’s core libraries like collections, caching, math, primitives, concurrency, networking, common annotations, string processing, I/O, reflection and many others. It is very well designed API. Guava is designed, implemented and maintained by Google Engineers like <a href="https://plus.google.com/113026104107031516488/about" target="_blank">Kevin Bourrillion</a> and <a href="https://plus.google.com/+KurtAlfredKluever/about" target="_blank">Kurt Alfred Kluever</a>, etc.<br /></p>

<p>Guava follows almost all the excellent patterns and practices mentioned in <a href="http://www.amazon.com/Effective-Java-Edition-Joshua-Bloch/dp/0321356683" target="_blank">Effective Java book</a> written by <a href="https://plus.google.com/113200173329286634669/about" target="_blank">Joshua Bloch</a>, who has designed the impeccable Java Collections API while he was at Sun. Later he joined Google. Under his mentor-ship, Google Guava got wings and became a very well designed and effective API, useful for many situations and scenarios with an ever-growing feature list. I ensure I add Guava dependency as the first thing to my Gradle or Maven build script. Guava makes <code>Java</code> code a lot more readable, clean, simple and elegant. It utilises the Java generics very well.<!--more--><br />
<br />
Consider the following example which I tweeted few months back.<br />
<a href="https://twitter.com/P7h/status/195895898146996224" imageanchor="1" style="margin-left: 1em; margin-right: 1em;" target="_blank"><img src="http://p7h.org/assets/images/Guava_Sample.png" alt="" /></a></p>

<p>Which of the above versions looks fine? Obviously the second option, aint it?
There are many such examples where Guava wins by a margin compared to normal Java code and or other libraries like commons, etc.</p>

<p>Guava also helps for [in a way] functional programming too. There are few options which are really helpful there as well. Having said that, Guava creators <a href="https://code.google.com/p/guava-libraries/wiki/FunctionalExplained" target="_blank">implore the developers</a> not to litter code with too much functional programming which might lead to unreadable code.</p>

<p>I will start with writing few posts on Google Guava with the tag, “LearningGuava”. I have been using Guava extensively in almost every project of mine since few years. This will not only help some one else looking for info or starting on Google Guava, but as well as for me also so that I will remember in future if I need any quick snippet on something specific with Guava usage. That being the motivation, I hope it will be of good experience for you and me as well.</p>

<p>This post will list all the posts written for Google Guava. This post kinda serves as an Index and quick reference of my Google Guava posts.</p>

<p><a href="http://p7h.org/blog/categories/learningguava/" target="_blank">Learning Guava Series</a>:<br />
<a href="http://p7h.org/blog/2014/01/26/load-properties-file-using-guava/" target="_blank">Load properties file using Guava</a><br />
<a href="http://p7h.org/blog/2014/01/29/guava-stopwatch/" target="_blank">Calibrating time using Stopwatch</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Presented Storm at The Fifth Elephant, 2013 ]]></title>
    <link href="http://p7h.org/blog/2013/07/15/presented-storm-at-fifth-elephant-2013/"/>
    <updated>2013-07-15T00:00:00+01:00</updated>
    <id>http://p7h.org/blog/2013/07/15/presented-storm-at-fifth-elephant-2013</id>
    <content type="html"><![CDATA[<p>On 11th July, 2013 I hosted a workshop on “Big Data, Real-time Processing and Storm” at <a href="http://fifthelephant.in/2013/workshops" target="_blank"><strong>The Fifth Elephant, 2013</strong></a> in Bangalore.<br />
The source code I used in this workshop can be found on my <strong><a href="http://github.com/P7h" target="_blank">GitHub</a></strong> account.<br />
I have also started curating a <a href="http://j.mp/YrDgcs" target="_blank"><strong>Bit.ly bundle</strong></a> for Storm and Big Data.<br />
I have shared the slides of this session both on Slideshare and SpeakerDeck.
<!--more--></p>

<iframe frameborder="0" width="650px" height="486" marginheight="0" marginwidth="0" scrolling="no" src="http://www.slideshare.net/slideshow/embed_code/24202814" style="border-width: 1px 1px 0; border: 1px solid #CCC; margin-bottom: 5px;" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen=""></iframe>
<p><strong><a href="http://www.slideshare.net/prashanthvvbabu/fifth-elephant-2013-storm" target="_blank" title="Storm @ Fifth Elephant 2013">Storm @ Fifth Elephant 2013</a></strong> from <strong><a href="http://www.slideshare.net/prashanthvvbabu" target="_blank">Prashanth Babu</a>
<br /></strong></p>

<p>If you prefer SpeakerDeck, please find the slides of the presentation deck at <strong><a href="https://speakerdeck.com/p7h/big-data-real-time-processing-and-storm" target="_blank">SpeakerDeck</a></strong>.
<script async="" class="speakerdeck-embed" data-id="d65c1130cdfc01304c5c5a08bad3805a" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"></script></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My upcoming workshop on Storm at The Fifth Elephant, 2013]]></title>
    <link href="http://p7h.org/blog/2013/05/25/workshop-on-storm-at-fifth-elephant/"/>
    <updated>2013-05-25T00:00:00+01:00</updated>
    <id>http://p7h.org/blog/2013/05/25/workshop-on-storm-at-fifth-elephant</id>
    <content type="html"><![CDATA[<p><a href="http://fifthelephant.in/2013/" target="_blank">The Fifth Elephant</a> is a conference in Bangalore, India which focuses on Big Data and Analytics. Its a community powered conference. This means, as highlighted in their website, it is “Of the Community, By the Community, For the Community”. So, any one can propose a session as such for the conference in the <a href="http://funnel.hasgeek.com/fifthel2013/" target="_blank">Funnel</a>. Participants who have purchased conference tickets can vote on session proposals.<br /></p>

<p>In <a href="http://fifthelephant.in/2012/" target="_blank">2012 edition</a>, Fifth Elephant with more than 50 sessions, attracted 600+ participants from many MNCs, startups alike. This 2-day conference was preceded by a one-day workshop sessions as well due to the overwhelming demand. The biggest USP of any of the HasGeek organized conferences [other than being community powered conferences] is, they live stream most of the sessions and they also upload all the recorded videos to <a href="http://www.youtube.com/user/hasgeek/videos" target="_blank">Youtube</a> and / or <a href="http://hasgeek.tv/fifthelephant/" target="_blank">HasGeek TV</a>.<br /></p>

<p>I gave a session on <i>Introduction to Pig</i> at The Fifth Elephant last year. I have written about it previously <a href="http://p7h.blogspot.in/2013/01/intro-to-pig.html" target="_blank">here</a>.<br />
<!--more--></p>

<p>The Fifth Elephant is back this year. Its even better with a dedicated day for Workshops at the same venue and the regular 2-day Conference on Big Data, Storage and Analytics and also with the product demos and hacker corners. There are some wonderful sessions proposed including one on Neo4J, Julia, etc and few sessions have already been selected by the Program Committee.<br /></p>

<p>I have been working on Big Data especially on Hadoop Ecosystem since more than 2 years now. I am fascinated by Big Data and various tools / frameworks which help analyze such large amounts of data. During this time, I came across <a href="https://storm.apache.org/" target="_blank">Storm</a>, which not just analyzes the Big Data, but analyzes in real-time. Yes, real-time very unlike Hadoop, which is basically batch-processing. I worked on couple of use cases and processed the streaming live data in really real-time using Storm. I can quote streaming tweets as my main source of real-time data , which I processed for multiple use cases using Storm.<br /></p>

<p>This year I have proposed a session on Storm titled <a href="http://funnel.hasgeek.com/fifthel2013/652-big-data-real-time-processing-and-storm" target="_blank">“Big Data, Real-time Processing and Storm”</a> and it has been accepted as the first workshop this time around. I will be speaking on 11th July, 2013. It will be a live-coding session, which will help the participants understand and appreciate Storm as one of the better alternatives of Hadoop. Below is the outline of this workshop.</p>

<iframe allowfullscreen="" frameborder="0" height="486" marginheight="0" marginwidth="0" mozallowfullscreen="" scrolling="no" src="http://www.slideshare.net/slideshow/embed_code/17823469" style="border-width: 1px 1px 0; border: 1px solid #CCC; margin-bottom: 5px;" webkitallowfullscreen="" width="650px"> </iframe>
<p><strong> <a href="http://www.slideshare.net/prashanthvvbabu/big-data-realtime-processing-and-storm" target="_blank" title="Big Data, Real-time Processing and Storm">Big Data, Real-time Processing and Storm</a> </strong> from <strong><a href="http://www.slideshare.net/prashanthvvbabu" target="_blank">Prashanth Babu</a></strong> <br /></p>

<p>I have also uploaded the slides of the outline of this workshop to <a href="https://speakerdeck.com/p7h/big-data-real-time-processing-and-storm" target="_blank">SpeakerDeck</a>.<br /></p>

<p>Check the above slides and do let me know if you have any feedback and / or comments on this outline for the workshop.<br /></p>

<p>Wish me good luck on <a href="https://twitter.com/P7h" target="_blank">@P7h</a>. And also if you happen to be there in this Conference, do come and say hi.<br /></p>

<p><strong>Update</strong>:<br />
Please find the complete slides of this workshop session <a href="http://p7h.org/blog/2013/07/15/presented-storm-at-fifth-elephant-2013/" target="_blank">here</a>.<br /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Open Source licenses]]></title>
    <link href="http://p7h.org/blog/2013/05/20/open-source-licenses/"/>
    <updated>2013-05-20T00:00:00+01:00</updated>
    <id>http://p7h.org/blog/2013/05/20/open-source-licenses</id>
    <content type="html"><![CDATA[<p>Understanding Open Source licenses always turns out to be rather too difficult. At least I always have had issues in understanding which Open Source license is too restrictive and which is a bit liberal.<br /></p>

<p>After looking around for some time, I found the following 3 alternatives for easy understanding of the terms of few of the Open Source licenses.
<!--more-->
<br /></p>

<h3 id="alternative1">Alternative#1:</h3>
<p><a class="g-profile" href="http://plus.google.com/101174951617223562800" target="_blank">Brian Fitzpatrick</a> and <a class="g-profile" href="http://plus.google.com/106739423424023436001" target="_blank">Dan Bentley</a> have made a brilliant flow chart for Open Source licenses. It is pretty simple and easy to understand.
<a href="http://cl.ly/5nAo" imageanchor="1" style="margin-left: 1em; margin-right: 1em;" target="_blank"><img src="http://p7h.org/assets/images/OSS License.png" alt="OSS Licenses" /></a><br /></p>

<h3 id="alternative2">Alternative#2:</h3>
<p><a class="g-profile" href="http://plus.google.com/113672091552048390436" target="_blank">Marakana</a> have another interesting flowchart for understanding Open Source licenses.<br />
<em>Update</em>: The actual link for the below image is not working anymore.
<a href="https://thenewcircle.com/s/post/1030/understanding_open_source_licenses" imageanchor="1" style="margin-left: 1em; margin-right: 1em;" target="_blank"><img src="http://p7h.org/assets/images/OSS-licenses.png" alt="OSS Licenses" /></a><br /></p>

<h3 id="alternative3">Alternative#3:</h3>
<p>And finally another option to understand Open Source licenses is <a href="http://www.tldrlegal.com/" target="_blank"><b>tl;drLegal</b></a> Website, which summarizes and explains Open Source licenses in simple terms and in plain English. Its a pretty decent website which is fast and also very intuitive and easy to use. Just key in the name of the License you want to read about. The website will do the rest with a quick summary and also the full text of this particular license.<br /></p>

<p>I always look up to one of these alternatives when I am in doubt about licensing terms of a particular Open Source License. And when I need to check the complete text of a license, I usually use <a href="http://www.tldrlegal.com/" target="_blank"><b>tl;drLegal</b></a> Website.<br /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My presentation on 'Introduction to Pig']]></title>
    <link href="http://p7h.org/blog/2013/01/26/intro-to-pig/"/>
    <updated>2013-01-26T00:00:00+00:00</updated>
    <id>http://p7h.org/blog/2013/01/26/intro-to-pig</id>
    <content type="html"><![CDATA[<p>I conducted a 2-hour <a href="http://fifthelephant.in/2012/workshop-pig" target="_blank">workshop</a> on “Introduction to Pig” at <a href="http://fifthelephant.in/" target="_blank">The Fifth Elephant</a> - a community-powered conference on Big Data and ecosystem - at Bangalore, India on 26th July, 2012.<br /></p>

<p>As part of this workshop, I have touched a bit on Hadoop, MapReduce and Hive. But as the title says, the focus was on Apache Pig. I also demoed few usecases of execution of Java MapReduce, Hive and Pig. And also a brief overview and demo of Twitter’s <a href="https://github.com/twitter/ambrose" target="_blank">Ambrose</a> UI for visualizing Pig MapReduce jobs.
<!--more--></p>

<p>This presentation gives a basic understanding of:</p>

<ul>
  <li>Big Data</li>
  <li>Basics of Hadoop and MapReduce</li>
  <li>Landscape of Hadoop ecosystem</li>
  <li>Introduction to Apache Pig</li>
  <li>Basics of Pig and Pig Latin</li>
  <li>Pig vs. Hadoop MR</li>
  <li>Pig vs. SQL and Pig vs. Hive</li>
  <li>Twitter Ambrose for visualizing Pig MR Jobs</li>
</ul>

<p>Here are the slides of my presentation.
<br /></p>

<iframe src="http://www.slideshare.net/slideshow/embed_code/16190473" width="615px" height="486px" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC;border-width:1px 1px 0;margin-bottom:5px" allowfullscreen="" webkitallowfullscreen="" mozallowfullscreen=""> </iframe>
<div style="margin-bottom:5px"><strong> <a href="http://www.slideshare.net/prashanthvvbabu/the-fifthelephant-2012handsonintrotopig" title="Introduction to Pig" target="_blank">Introduction to Pig</a> </strong> from <strong><a href="http://www.slideshare.net/prashanthvvbabu" target="_blank">Prashanth Babu</a></strong>

<br />
If you prefer SpeakerDeck, please find the slides of the presentation deck at <strong><a href="https://speakerdeck.com/p7h/introduction-to-pig" target="_blank">SpeakerDeck</a></strong>.<br />
<script async="" class="speakerdeck-embed" data-id="b49b034049e90130e7cf22000a1f8082" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"></script>

Code used in the demos during this workshop can be found on [GitHub](https://github.com/P7h/IntroToPig &#8220;Introduction to Pig&#8221;).
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Aaron Swartz Memorial at New York]]></title>
    <link href="http://p7h.org/blog/2013/01/20/aaron-swartz-memorial/"/>
    <updated>2013-01-20T00:00:00+00:00</updated>
    <id>http://p7h.org/blog/2013/01/20/aaron-swartz-memorial</id>
    <content type="html"><![CDATA[<p>Aaron Swartz, a very accomplished and a highly talented nerd committed suicide last Friday, i.e. 11th January, 2013 at an young age of 26 years. So many people have written so much about him. Check the complete <a href="http://en.wikipedia.org/wiki/Aaron_Swartz">Wikipedia</a> page and check the <a href="http://en.wikipedia.org/wiki/Aaron_Swartz#References" target="_blank">References</a> section of his Wikipedia page for more info and other articles written by his friends. He has left wonderful impressions on Reddit, Creative Commons, SOPA, Markdown, RSS, web.py to name a few of his outstanding contributions.<br /></p>

<div style="text-align: center;"><a href="http://www.flickr.com/photos/quinn/870253651/" target="_blank" title="Aaron by quinnums, on Flickr"><img alt="Aaron Swartz" height="500" src="http://farm2.staticflickr.com/1150/870253651_9b076ba1b3.jpg" width="500" /></a></div>
<!--more-->

<p>Aaron’s <a href="http://www.rememberaaronsw.com/">memorial</a> was held on Saturday, 19th January, 2013 at Cooper Union, New York. Here is the complete set of recorded videos from his memorial which are hosted on <a href="http://www.livestream.com/democracynow/folder?dirId=0545b862-1026-4b88-86ff-409745806958">livestream</a>. There are totally 6 videos which you must checkout to understand what are his contributions and how talented a person he was and what impressions he has left people with, even such an young age.<br /></p>

<p>If you are hard-pressed for time, then ensure you at least check the message from Taren Stinebrickner-Kauffman, partner of Aaron, embedded below. It is really inspiring.<br /></p>

<div style="text-align: center;"><iframe frameborder="0" height="385" scrolling="no" src="http://cdn.livestream.com/embed/democracynow?layout=4&amp;clip=pla_f83c80fe-0fc0-474c-9936-efe8659466f6&amp;color=0xe7e7e7&amp;autoPlay=false&amp;mute=false&amp;iconColorOver=0x888888&amp;iconColor=0x777777&amp;allowchat=true&amp;height=385&amp;width=640" style="border: 0; outline: 0;" width="640"></iframe><br />

Rest in peace Aaron!!
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Eclipse startup options or JVM Settings]]></title>
    <link href="http://p7h.org/blog/2012/12/29/eclipse-startup-options-or-jvm-settings/"/>
    <updated>2012-12-29T00:00:00+00:00</updated>
    <id>http://p7h.org/blog/2012/12/29/eclipse-startup-options-or-jvm-settings</id>
    <content type="html"><![CDATA[<p>In continuation to my other post on <a href="http://p7h.blogspot.com/2012/12/intellij-idea-tuning-parameters.html" target="_blank">tuning IntelliJ IDEA</a>, in this post I am detailing the startup options [which are also called JVM Settings] for Eclipse IDE. Eclipse startup is controlled by the options in <code>eclipse.ini</code> file present directly under Eclipse installation folder [i.e. $ECLIPSE_HOME]. By default, Eclipse comes with a set of values in this file. But those values are not optimized and might cause issues and / or hangs in large projects which might have considerably bigger codebase. These can be tuned further for better performance.<br /></p>

<p>My startup options in my current version of Eclipse Juno i.e. v4.2.1 are listed below.
<!--more--></p>

<div><script src="https://gist.github.com/4392224.js"></script>
<noscript><pre><code>-startup
plugins/org.eclipse.equinox.launcher_1.3.0.v20120522-1813.jar
--launcher.library
plugins/org.eclipse.equinox.launcher.win32.win32.x86_64_1.1.200.v20120522-1813
-vm
C:/Warez/Java/JDK7.0_10/jre/bin/server/jvm.dll
-showsplash
org.eclipse.platform
--launcher.XXMaxPermSize
256m
--launcher.defaultAction
openFile
-product
org.eclipse.epp.package.jee.product
--launcher.defaultAction
openFile
--launcher.XXMaxPermSize
256M
-vmargs
-server
-Declipse.p2.unsignedPolicy=allow
-Xms1024m
-Xmx1024m
-Xmn128m
-Xss4m
-XX:PermSize=256m
-XX:MaxPermSize=256m
-XX:+UseG1GC
-XX:+UseParallelGC
-Xverify:none
-XX:+UseFastAccessorMethods
-Dosgi.requiredJavaVersion=1.5
-Dhelp.lucene.tokenizer=standard</code></pre></noscript></div>

<p>Please use these options as a reference and update <code>eclipse.ini</code> file [please do take a backup of this file prior to updating it]. Also, one more important point to note is, use the latest <a href="http://www.oracle.com/technetwork/java/javase/downloads/index-jsp-138363.html" target="_blank">Sun / Oracle JDK</a> for starting Eclipse. This also has a profound effect on the Eclipse startup time as well as the IDE functionality with a decent sized codebase.<br /></p>

<p>Finally, in case you were looking for tuning the startup options of IntelliJ IDEA, please refer my earlier post on tuning <a href="http://p7h.org/2012/12/intellij-idea-tuning-parameters.html" target="_blank">startup parameters for IDEA</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Dark Knight Rises ultimate trilogy trailer]]></title>
    <link href="http://p7h.org/blog/2012/12/27/the-dark-knight-rises-ultimate-trilogy/"/>
    <updated>2012-12-27T00:00:00+00:00</updated>
    <id>http://p7h.org/blog/2012/12/27/the-dark-knight-rises-ultimate-trilogy</id>
    <content type="html"><![CDATA[<p>Wonderfully put together ultimate trilogy trailer of “<a href="http://en.wikipedia.org/wiki/The_Dark_Knight_Rises" target="_blank">The Dark Knight Rises</a>”, <a href="http://en.wikipedia.org/wiki/Christopher_Nolan" target="_blank">Christopher Nolan</a>’s Batman series. Christopher Nolan’s taking is brilliant as always. Apart from him, Hans Zimmer’s background score is excellent. I concur with the comment in the below Youtube page which says: “Without Hans Zimmer this trilogy wouldn’t be nearly as epic as it is”. If you have any doubts, you should check out the Original Motion Picture Soundtrack of <i>The Dark Knight Rises</i> on <a href="http://www.amazon.com/The-Dark-Knight-Rises-Soundtrack/dp/B008645YEE" target="_blank">Amazon</a> or <a href="http://www.flipkart.com/dark-knight-rises/p/itmdbvq7g22yjmks?pid=DGADBVQ7WC4RGX8C" target="_blank">Flipkart</a>.<br /></p>

<p>The only thing I missed in this trailer is the voice of Bane i.e. <a href="http://en.wikipedia.org/wiki/Tom_Hardy" target="_blank">Tom Hardy</a>. </p>

<iframe allowfullscreen="allowfullscreen" frameborder="0" height="480" src="https://www.youtube.com/embed/1T__uN5xmC0" width="800"></iframe>

<p><br /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Eclipse Plugins]]></title>
    <link href="http://p7h.org/blog/2012/12/27/eclipse-plugins/"/>
    <updated>2012-12-27T00:00:00+00:00</updated>
    <id>http://p7h.org/blog/2012/12/27/eclipse-plugins</id>
    <content type="html"><![CDATA[<p><a href="http://eclipse.org/" target="_blank">Eclipse</a> was my main IDE for all my JavaEE and Web development all the time in my career. For all plain Java development and Android app development, I used to revert to <a href="http://www.jetbrains.com/idea/" target="_blank">IntelliJ IDEA</a> Community Edition, which allows only plain Java development and not Enterprise Java development i.e. JavaEE or Web Development [Spring, Hibernate, Grails, etc]. For more info on what is allowed and what is not allowed in Community Edition, please check <a href="http://www.jetbrains.com/idea/features/editions_comparison_matrix.html" target="_blank">matrix on CE and Ultimate Editions</a>.<br />
Post the <a href="http://p7h.blogspot.com/2012/12/jetbrains-mayan-doomsday-special-offers.html" target="_blank">Mayan Doomsday Offer</a> by JetBrains, thanks to the 75% steep discount on 20th December, 2012 I now have IntelliJ IDEA Ultimate Edition as well <em>and have been renewing every year after that</em>.<br />
<!--more--></p>

<p>Eclipse is open source and is free to use. It is a thriving community for individuals and organizations which collaborate on commercially-friendly open source software. So, over a period of time Eclipse grew on all developers and almost everyone uses it as their main driver for development. And what’s more with Scala, Groovy and Android teams giving support for Eclipse as the first IDE has given it a good momentum in the past few years.<br /></p>

<p>The plugin ecosystem is huge in Eclipse and in fact, these plugins have helped Eclipse grow as a platform what it is today. Such is the popularity of plugins in Eclipse ecosystem that they have also launched <a href="http://marketplace.eclipse.org/" target="_blank">Marketplace</a> for Eclipse plugins. If something is missing in Eclipse, don’t worry, just check the Marketplace for the plugin or else you can develop a plugin in no time actually. That has been the mindset of a lot of Java developers in Eclipse ecosystem. There are thousands of plugins available for Eclipse right from customizing the IDE to Maven integration to Python IDE to Spring IDE, for Checkstyle, PMD, FindBugs, etc. <br /></p>

<p>With all my prior experience in using Eclipse, I have some goto plugins which I install the moment I get a brand new Eclipse version. Here is the list of all Eclipse plugins which I have used till now with a short description and the Eclipse Update Sites of the plugin.</p>
<div><script src="https://gist.github.com/4389668.js"></script>
<noscript><pre><code>AnyEdit: Adds several new tools to the context menu of text-based Eclipse editors, to output consoles, to Eclipse main menu and editor toolbar -- http://andrei.gmxhome.de/eclipse
Code Recommenders: Intelligent code completion -- http://download.eclipse.org/recommenders/updates/stable/e42/
EasyShell: Opens shell window, runs selected file in the shell; opens explorer window (or nautilus / konqueror) and copies path -- http://pluginbox.sourceforge.net
Eclipse Color Themes: Variety of Color Themes for Eclipse -- http://eclipse-color-theme.github.com/update
EditBox: For highlighting the background of the source code -- http://editbox.sourceforge.net/updates
FindBugs: For static analysis to look for bugs in Java code  -- http://findbugs.cs.umd.edu/eclipse
Google CodePro AnalytiX: For improving software quality and reducing developments costs and schedules -- http://dl.google.com/eclipse/inst/codepro/latest/3.7
MouseFeed: For learning keyboard shortcuts in Eclipse -- http://update.mousefeed.com
SnipMatch: Code snippet search tool for Eclipse -- http://languageinterfaces.com/eclipsePlugin</code></pre></noscript></div>

<p>Hope this was of some help to you.<br />
Also, if you are interested in IntelliJ IDEA plugins, please check my <a href="http://p7h.blogspot.com/2012/12/intellij-ide-plugins.html" target="_blank">earlier post</a> which lists all the IntelliJ IDEA plugins I use.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Guava toString() method generator for IntelliJ IDEA]]></title>
    <link href="http://p7h.org/blog/2012/12/22/guava-tostring-method-gen-for-intellij-idea/"/>
    <updated>2012-12-22T00:00:00+00:00</updated>
    <id>http://p7h.org/blog/2012/12/22/guava-tostring-method-gen-for-intellij-idea</id>
    <content type="html"><![CDATA[<p><a href="http://www.jetbrains.com/idea/" target="_blank">IntelliJ IDEA</a> comes bundled with <code>toString()</code> plugin. If you check the plugins in Settings, you should find GenerateToString plugin, which generates <code>toString()</code> method with options for String concat, StringBuffer, StringBuilder and ToStringBuilder (of Apache Commons) for generating this method.</p>

<p><a href="http://code.google.com/p/guava-libraries/" target="_blank">Google Guava</a> has even better helper method for generating <code>toString()</code> method for a JavaBean or POJO, which is both clutter free and has a very consistent format; in the form of <a href="http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/base/Objects.html#toStringHelper(java.lang.Class)" target="_blank">Objects.toStringHelper(this)</a>. It looks more elegant than any of the above solutions, actually. Also, as I make it a point to use Google Guava in all my projects, I have defined the following template in my <code>toString()</code> method generator settings in IntelliJ IDEA.
<!--more--></p>

<div><script src="https://gist.github.com/4388630.js"></script>
<noscript><pre><code>/**
 * Guava API toString() method generator for a JavaBean / POJO.
 * @return String representation of all the attributes of the bean.
 */
public String toString() {
    #set ($autoImportPackages = &quot;com.google.common.base.Objects&quot;)
    return Objects.toStringHelper(this)
    #foreach ($member in $members)
        .add(&quot;$member.name&quot;, $member.accessor)
    #end
        .toString();
}</code></pre></noscript></div>

<p>Follow the steps mentioned below for adding this template to your IntelliJ IDEA [picked up from <a href="http://stackoverflow.com/a/9445402" target="_blank">SO</a>]:</p>

<ol>
  <li>Go inside a Java Class in an editor in IntelliJ IDEA.</li>
  <li>Hit Alt + Insert to popup the “Generate” menu.</li>
  <li>Choose <code>toString()</code>.</li>
  <li>Click the “Settings” button.</li>
  <li>Go to the “Templates” tab.</li>
  <li>Create a new template named “Guava toString gen” (or any name you prefer).</li>
  <li>Add the above code to the template.</li>
</ol>

<p>Yes, its that simple!!  After configuring the above template, whenever you want to generate a <code>toString()</code> method for a Class, IntelliJ IDEA generates <code>toString()</code> using Guava template you have added just now.</p>

<p>Now, go ahead and give this a try and also check the other method <a href="http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/base/Objects.ToStringHelper.html#omitNullValues()" target="_blank">omitNullValues()</a> which might be useful in some scenarios.</p>

<p>Also, as a bonus tip, Guava’s <a href="http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/base/Objects.html" target="_blank">Objects</a> class also has 2 awesome helper methods which aide in writing readable <a href="http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/base/Objects.html#equal(java.lang.Object, java.lang.Object)" target="_blank">equals()</a> and <a href="http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/base/Objects.html#hashCode(java.lang.Object...)" target="_blank">hashcode()</a> methods. You should try them too.</p>
]]></content>
  </entry>
  
</feed>
